# 느려진 서비스, 어디서부터 봐야 할까

사용자는 무언가를 실행할 때 동작하기까지 걸린 시간으로 성능을 판단한다.  
실제로는 다양한 성능 지표가 성능과 관련되어 있고, 그 중에서도 서버 성능과 관련 있는 중요한 지표를 2가지 꼽자면 응답 시간과 처리량을 들 수 있다.

## 처리량과 응답 시간

> 응답 시간 감소는 처리량 증가로 이어진다.

### 응답 시간

응답시간은 1. API 요청 전송시간 2.서버의 처리시간 3. API 응답 전송 시간으로 나뉜다.  
서버 개발자는 주로 2. 서버의 처리시간을 확인한다. 서버의 처리 시간은 다음과 같다.

- 로직 수행
- **DB 연동(SQL 실행)**
- **외부 API 연동**
- 응답 데이터 생성(전송)
  이 중에서도 DB연동, 외부 API 연동이 큰 비중을 차지한다.

### 처리량

처리량은 단위 시간당 시스템이 처리하는 작업량을 의미한다. 흔히 TPS, RPS로 처치량을 나타낸다.  
최대 TPS는 시스템이 처리할 수 있는 **최대 요청 수**를 의미한다. 최대 TPS를 초과하면 서버는 초과된 요청을 나중에 처리한다.

응답 시간 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 2가지 방법을 고려해야 한다.

- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기
- 처리 시간 자체를 줄여 대기 시간 줄이기
  두 방법을 적용하면 TPS를 높일 수 있다.

성능을 개선하려면 먼저 현재 서버의 **TPS**와 **응답 시간**을 알아야 한다.  
트래픽이 많은 시간대의 TPS를 측정하고 목표 TPS와 응답 시간을 설정하고 효과적인 성능 개선안을 도출해야 한다.  
만약 트래픽이 많은 시간대의 TPS 가 10개이고, 최대 TPS가 5개이고, 응답시간이 1초라고 하자. 최대 TPS를 늘릴 수 있는 방법으로는 동시에 처리할 수 있는 요청 수를 10개로 늘리는 방법과 응답시간은 0.5초로 줄여서 TPS가 10개가 와도 최대 1초가 걸리는 것을 보장해주는 방법이 있다.  
**트래픽 많은 시간대의 TPS와 응답 시간 측정 -> 목표 도출 -> 실행**

TPS를 확인하는 가장 간단한 방법은 모니터링 시스템을 활용하는 것이다. 스카우터, 핀포인트, 뉴렐릭 같은 도구 활용.

```
많은 모니터링 시스템이 TPS를 구할 때 근사치를 사용한다. 평균을 낸다는 말이다.
엘라스틱서치나 핀포인트 같은 도구가 없다면 접근 로그를 파싱해서 TPS를 구해도 된다. 다소 번거롭긴 하지만 약간의 리눅스 명령어와 코딩만으로도 TPS를 산출할 수 있다.
```

## 서버의 성능 개선 기초

### 병목 지점

최대 TPS를 초과하는 트래픽이 유입되면 그때 성능 문제가 발생하게 된다. 시스템이 제공할 수 있는 최대 TPS르 높이지 않으면 증가하는 트래픽을 적절히 처리할 수 없다.  
TPS를 높이려면 먼저 성능 문제가 발생한 지점을 찾아야한다. 문제 지점을 찾는 간단한 방법은 **처리 시간이 오래 걸리는 작업을 식별**하는 것이다. 성능 문제는 응답 시간이 길어지면서 발생하는 경우가 많기 때문이다. 모니터링 도구가 유용하고 대부분의 모니터링 도구는 실행 시간 추적 기능을 제공하므로 이 기능을 활용하면 성능 문제가 발생하는 시점에 어떤 코드에서 실행 시간이 오래 걸렸는지 찾을 수 있다. 적절한 모니터링 도구가 없다면 로그라도 남겨야한다. 의심되는 코드의 실행 시간을 로그로 남겨두면 나중에 성능 문제가 다시 발생했을 때 개선할 부분을 찾는 데 도움이 된다.

**병목 지점을 찾기 위해 모니터링 도구를 활용하거나 로그를 남겨서 이상하게 처리시간이 오래걸리는 부분을 찾으면 그 부분이 병목 지점인 것이다.**

### 수직 확장과 수평 확장

**수직 확장**  
성능 문제를 일으키는 원인을 찾았다면 빠르게 적용할 수 있는 개선안을 도출해야한다.
급한 불을 끄는 방법 중 하나는 수직 확장(scale-up) 하는 것이다. 수직 확장은 CPU, 메모리, 디스크 등의 자원을 증가시키는 것을 말한다. 더 빠른 CPU, CPU 코어 수 늘리기, 메모리 확장, 디스크를 SSD로 바꾸는 것만으로 성능이 개선될 수 있다. 클라우드 환경에서 비교적 빠르게 시도할 수 있는 방법이다.

```
메모리 증설의 예시
서버 메모리가 512MB일 때 동시에 처리할 수 있는 요청 개수가 200개라면 동시 요청이 250개로 늘어나는 것만으로도 응답 시간이 증가한다.(최대 TPS를 초과한 요청에 대해서 대기를 해야하므로) 이때 서버 메모리를 1GB로 증설하기만 해도 TPS를 늘릴 수 있다.
```

**수평 확장**  
수직 확장은 비용이 많이 든다. 한 대의 장비가 감당할 수 있는 요량에도 한계가 있다. 따라서 트래픽이 증가하면 서버를추가로 투입해 TPS를 높이는 방법도 고려해야 한다. 이게 수평 확장(scale-out) 이라고 한다.

> **로드 밸런서**  
> 서버가 두대 이상이면 로드 밸런서(load balancer)가 필요하다. 로드 밸런서는 사용자 트래픽을 각 서버에 골고루 분배해서 서버에 사ㅛㅇ자 트래픽이 몰리지 않도록 한다. 이를 통해 전체 서버 자원을 효율적으로 활용할 수 있다.  
> 로드 밸런서가 트래픽을 알맞게 분산시키기 위해 사용하는 방식은 1. 정적인 방식과 2. 동적인 방식으로 나뉜다.
>
> - 정적인 방식: 라운드로빈과 IP 해시 방식
> - 동적인 방식: 서버의 현재 상태에 따라 트래픽을 분산하는 방식을 트래픽이 낮은 서버에 요청을 보내는 형태로 동작한다.

**서버를 추가하기 위해 고려해야할 점**  
실제 병목 지점이 어디인지 파악하는 것이 중요하다. DB에서 성능 문제가 발생하고 있는데 서버를 추가하면 불에 기름 붓는 격이다. DB에 문제가 있는 상황에서 DB를 사용하는 서버를 더 늘리면 DB에 가해지는 부하가 더 커지고 성능 문제는 더 악화된다.  
외부 API의 성능 문제인 경우도 마찬가지이다. DB나 외부 API에 성능 문제가 발생하지 않는 범위 내에서만 수평확장을 해야 효과각 있다.

### DB 커넥션 풀

DB를 사용하려면 다음과 같이 3단계를 거친다.

1. DB에 연결한다.
2. 쿼리를 실행한다.
3. 사용이 끝나면 연결을 종료한다.
   서버와 DB는 **네트워크 통신**을 통해 연결된다. 이때 네트워크 연결을 **생서하고 종료하는 데 걸리는 시간은 0.5초에서 1초 이상 소요**되기도 한다. 실행시간이 10ms에 불과한 짧은 쿼리를 실행하기 위해 연결과 종료에 50ms가 걸린다고 하자. 단순히 계산해도 전체 처리 시간인 60ms 중 80% 이상이 DB 연결 및 종료에 쓰이게 된다.  
   **네트워크에서 DB를 연결하고 종료하는 시간은 전체 응답 시간에 영향을 준다.**  
   이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다. **DB 커넥션 풀**은 DB에 연결된 커넥션을 미리 생성해서 보관하는 것이다. 스프링부트는 HikariCP를 커넥션 풀로 사용하며 Go 언어는 자체적으로 DB 커넥션 풀을 지원한다.  
   커넥션 풀은 다양한 설정을 제공한다. 그중 중요한 설정은 다음과 같다.

- 커넥션 풀 크기(또는 최소 크기, 최대 크기)
- 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
- 커넥션의 유지 시간(최대 유휴 시간, 최대 유지 시간)

### 커넥션 풀 크기

커넥션 풀 크기는 커넥션 풀에 미리 생성해둘 커넥션 개수를 지정하는 설정이다. 커넥션 풀 크기는 커넥션 풀 설정에서 가장 중요하다. DB 커넥션 풀 크기를 잘못 설정하면 성능에 큰 영향을 준다.
커넥션 풀 크기가 5이 경우, 서버에 6개의 요청이 동시에 들어왔을 때 이 중 5개 요청을 풀에서 커넥션을 가져올 수 있다. 나머지 1개 요청은 커넥션이 반환될 때가지 기다려야한다. 풀에서 커넥션을 얻기 위해 대기하는 시간을 줄이려면 전체 응답 시간과 TPS를 고려하여 커넥션 풀 크기를 지정해야한다.  
커넥션 풀의 크기가 5이고 한 요청에서 쿼리를 실행하는 데 0.1초라고 해보자. 이때 1초에 처리할 수 있는 요청수는 50이 된다. 동시에 50개의 요청이 들어와도 모두 1초 안에 처리가 끝난다. 어떤 요청은 최대 0.9초를 대기할 수도 있지만 1초 안에 처리가 끝난다.

반면 풀 크기가 5이고 한 요청의 쿼리 실행 시간이 0.5초라면 1초에 처리할 수 있는 요청 수는 10으로 줄어든다. 동시에 50개의 요청이 들어오면 어떤 요청은 최악의 경우 4.5초를 대기해야한다. 여기서 응답 시간을 줄이기 위해 커넥션 풀 크기를 50으로 늘려 모든 요청(최대 100개 요청을 1초에 처리 가능)을 0.5초 이내로 처리할 수 있다.  
커넥션 풀의 최소 크기와 최대 크기를 설정해서 트래픽의 증감 패턴에 맞게 설정할 수 있다.

> **트래픽이 순간적으로 급증**하는 패턴을 보인다면 커넥션 풀의 최소 크기를 최대 크기에 맞추는 것이 좋다.  
> **트래픽이 점진적으로 증가할 때**는 DB 연결 시간이 성능이 큰 영향을 주기 않지만 트래픽이 급증할 경우 DB 연결 시간도 성능 저하의 주요 원인이 될 수 있기 때문이다.

**커넥션 풀 설정 시 DB 상태도 봐야한다.**

커넥션 풀 크기를 무턱대고 늘리면 안된다. DB 상태를 보고 늘려야 한다. **DB 서버의 CPU 사용률이 80%에 육박하는 상황**에서 커넥션 풀 크기를 늘리면 **DB에 가해지는 부하가 더 커져 쿼리 실행 시간이 급격히 증가**할 수 있다. 이런 상태에서 커넥션 풀 크기를 늘리기보다는 오히려 커넥션 풀 크기를 유지하거나 줄여서 DB 서버가 포화 상태에 이르지 않도록 해야한다. 서버를 수평 확장하는 것도 커넥션 풀 크기를 늘리는 것과 동일한다. DB 서버의 상태를 면밀히 확인한 후에 수평 확장을 진행해야한다.

### 커넥션 대기 시간

커넥션 풀은 대기 시간을 설정할 수 있다. 대기 시간이란 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다릴 수 있는 최대 시간을 의미한다. 지정된 시간에 커넥션을 얻지 못하면 DB 연결 실패 에러가 발생한다.  
커넥션을 얻기 위해 대기하는 시간만큼 응답 시간도 길어지낟. 참고로 HikariCP의 기본 대기 시간은 30초이다. 즉, 최악의 경우 응답 시간이 30초를 넘길 수도 있다는 것을 의미한다. 따라서 **응답시간이 중요한 서비스는 커넥션 대기 시간을 가능한 짧게 설정해야 한다.** 트래픽의 양이나 서비스의 특성에 따라 차이는 있지만 보통의 경우라면 0.5초에서 2초 이내로 지정하자.  
대기시간이 짧으면 커넥션 풀이 모두 사용 중일 때 빠르게 '일시적 오류'와 같은 에러 응답을 사용자에게 보여줄 수 있다. 긴 대기 시간 때문에 긴 시간 동안 무응답 상태로 유지되는 것보다 빠르게 에러를 반환하는 것이 더 낫다. 커넥션을 얻지 못했을 때 빠르게 에러를 응답해야 서버의 부하가 증가하는 것도 방지할 수 있다.  
대기 시간이 30초인 경우 최악의 경우를 생각해보자.

- 커넥션 풀의 크기가 10
- 대기 시간이 30초
- 동시에 30개의 요청이 발생
- DB 서버에 부하가 걸리면서 쿼리 실행 시간이 10초로 늘어남.
  위 상황에서 동시에 30개의 요청이 들어오면 일단 10개 요청을 풀에서 커넥션을 꺼내와 쿼리를 실행한다. 대기하는 사람 중 절반이 5초를 기다리지 못하고 중간에 재요청을 하면 어떻게 될까?  
  풀에서 커넥션을 확보한 10개의 요청은 쿼리 실행시간 10초 중 절반인 5초를 실행한 상태이다. 클라이언트가 요청을 취소하더라도 서버는 일정 시간동안 하던 작업을 즉시 중단하지 않기 때문에 이 시점의 대기 중인 요청 수는 총 30개가 된다.  
  대기 중인 요청 수가 20 개에서 30 개로 증가하면서 서버가 동시에 처리해야 할 요청 수가 30 개에서 40개로 늘었다. 이처럼 몇 초 만에 요청을 취소하고 재요청이 반복되면 동시에 처리해야 할 요청 수는 계속 증가한다. 요청 수가 증가하면 그만큼 서버에 가해지는 부하도 커지게 된다.

커넥션 풀의 개수는 동일하고, 대기시간이 1초라면?

- 풀에서 커넥션을 확보한 10개의 요청은 쿼리를 2초간 실행하고 있음
- 커넥션을 확보하지 못한 20개의 요청은 오류 응답을 받음.
  길어야 1초가 지난 후 실패 응답이라도 받을 수 있다. 이처럼 대기시간을 짧게 설정하면 서버 부하를 일정 수준으로 유지할 수 있으며 서버를 안정적으로 운영하는 데 도움이 된다.

### 최대 유휴 시간, 유효성 검사, 최대 유지 시간

MySQL과 같은 DB는 클라이언트와 일정 시간 동안 상호작용이 없으면 자동으로 연결을 끊는 기능을 제공한다. 따라서 풀에 있는 커넥션이 일정 시간 동안 사용되지 않으면 DB와의 연결이 끊어질 수 있다. 예를 들어서 DB가 1시간 동안 상호작용이 없는 클라리언트의 연결을 종료하도록 설정되어 있다고 가정해보자. 만약 새벽 시간대에 1시간 이상 사용자가 없으면 커넥션 풀에 있는 모든 커넥션은 DB와의 연결이 끊기게 된다.

이때 DB와의 연결이 끊긴 커넥션을 사용하면 에러가 발생한다. 이런 에러를 방지하기 위해 커넥션 풀은 다음 2가지 기능을 제공한다.

- 최대 유휴시간 지정
- 유효성 검사 지원

**최대 유휴 시간**  
최대 유휴 시간은 사용되지 않은 커넥션을 풀에 유지할 수 있는 최대 시간을 의미한다.
DB에 설정된 비활성화 유지 시간보다 짧게 설정하면, DB가 연결을 끊기 전에 풀에서 커넥션을 제거할 수 있다.

**유효성 검사**  
유효성 검사는 커넥션이 정상적으로 사용할 수 있는 상태인지 여부를 확인하는 절차이다. 커넥션 풀의 구현 방식에 따라 커넥션을 풀에서 가져올 때 유효성을 검사하거나 주기적으로 검사할 수 있다. 이 과정을 통해 연결이 유효하지 않은 커넥션을 식별하고 풀에서 제거할 수 있다.
유효성 검사를 위해 실제 쿼리를 실행하기도 한다. 간단한 쿼리를 실행한다.

**최대 유지 시간**
커넥션의 LifeTime을 설정해주는 시간이다.

> 최대 유휴시 시간과 최대 유지 시간을 무한대로 설정하지 않는 것이 좋다. 커넥션 풀의 기본값을 확인 한 뒤 이 두 설정의 기본값이 무제한으로 되어 있다면 DB 설정을 참고하여 알맞게 적절한 값으로 지정해야 한다.

### 서버 캐시

응답 시간과 처리량을 높이기 위해 DB 서버를 수평 확장, 수직 확장으로 서버를 확장할 수 있다.
위 방법은 비용이 많이들고, DB 서버를 수평 확장 하더라도 **처리량**은 늘릴 수 있어도 **실행 시간**이 획기적으로 줄어들지 않는다.  
DB 서버를 확장하지 않고도 응답 시간과 처리량을 개선하고 싶다면 **캐시(cache)** 사용을 고려할 수 있다.  
DB뿐만 아니라 복잡한 계산 결과나 외부 API 연동 결과도 캐시에 보관하여 응답 시간을 줄이는 데 확용할 수 있다.

### 적중률과 삭제 규칙

캐시가 얼마나 효율적으로 사용되는지는 적중률로 판단할 수 있다. 캐시 적중률은 다음과 같이 계산한다.

- 적중률(hit rate) = 캐시에 존재한 건수 / 캐시에서 조회를 시도한 건수
  **적중률이 높을 수록** DB와의 연동이 줄어들고 곧 **응답 시간 감소**, **처리량 증가**, **DB 부하 감소**로 이어진다.  
  캐시의 적중률을 높이고 싶다면 캐시에 최대한 많은 데이터를 저장해 놓는 것이다. 하지만 캐시에 모든 데이터를 무작정 저장할 수 없다. 캐시는 메모리 자원을 사용하기 때문이다. 사용할 수 있는 메모리 용량은 한계가 있기에 캐시에 저장할 수 있는 데이터 개수나 크기도 제한된다.

캐시에 보관할 수 있는 데이터에 제한이 있으므로, 캐시가 가득 차 있는 상태에서 새로운 데이터를 캐시에 저장하면 기존에 있던 데이터 중 하나를 제거해야한다. 삭제할 대상을 선택할 때 주로 사용하는 규칙은 다음과 같다.

- LRU(Least Recently Used): 가장 오래전에 사용된 데이터를 제거한다.
- LFU(Least Frequently Used): 가장 적제 사용된 데이터를 제거한다.
- FIFO(First In First Out): 먼저 추가된 데이터를 먼저 삭제한다.
  많은 서비스에서 최신 데이터를 더 자주 조회하는 경향이 있다. 최신 기사를 많이 검색하지 시간이 지난 데이터는 조회 수가 낮다. 오래된 데이터는 미리 삭제하는 것이 좋다. 이를 위해 캐시에는 유효 시간(만료시간)을 설정하는 방식도 함께 사용한다.

### 로컬 캐시와 리모트 캐시

```
인-메모리 캐시
로컬 캐시는 인-메모리(In-memory) 캐시라고도 불린다. 메모리에 캐시 데이터를 보관하기 때문이다. 그런데 리모트 캐시로 많이 사용되는 레디스를 인-메모리 저장소라고 부르기도 한다. 디스크 대신 메모리를 저장소로 활용하기 때문에 이렇게 부른다고 들었다.
```

로컬 캐시 구현 기술로는 Caffeine(자바), go-cache(Go), node-cache(Node.js) 등이 있다. 로컬 캐시의 장점은 속도이다.

로컬 캐시와 리모트 캐시는 각각 장단점이 뚜렷하기 때문에 상황이나 용도에 맞게 선택해야한다. 절대적인 기준은 없으며 데이터 규모, 변경 빈도, 응답 시간, 처리량 등을 판단 기준으로 삼아 결정해야한다.

캐시에 보관할 데이터 규모가 작고 변경 빈도가 매우 낮다면 로컬 캐시로 충분하다.

### 캐시 사전 적재

트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려할 필요가 있다. 다음은 캐시에 미리 데이터를 저장하면 큰 효과를 볼 수 있는 가상의 사례를 만들어 본 것이다.

- G 앱 사용자는 300만 명이다.
- G 엡 서비스는 사용자에게 매달 정해진 날에 요금 정보를 보여준다.
- 해당 일자가 되면 전체 회원을 대상으로 요금 안내 푸시 알림을 발송한다.
- 푸시를 받은 사용자 중 일부는 G앱을 통해 이달의 요금 정보를 조회한다.
  위 사례에서 푸시 알림을 받은 사용자는 G앱을 실행해서 즉시 요금 정보를 조회한다. 푸시를 받자마자 절반의 사용자가 바로 확인한다면 150만 명이 동시에 접속하게 된다. 이때 요금 정보에 대한 캐시 적중률은 순간적으로 0%에 가까워질 수 있다.  
  이런 상황을 방지하는 방법 중 하나는 캐시에 데이터를 미리 넣어두는 것이다. 300만 명의 사용자에게 푸시 알림을 보내기 전에 각 사용자의 요금 정보를 캐시에 저장해두면 푸시를 받은 사용자가 한꺼번에 몰려올 때도 캐시 적중률은 99%에 가깝게 유지할 수 있으며, DB 부하가 집중되는 현상도 효과적으로 방지할 수 있다.

### 캐시 무효화

캐시를 사용할 때 반드시 신경써야할 점은 유효하지 않은 데이터를 적절한 시점에 캐시에서 삭제하는 것이다. 캐시에 보관된 데이터의 원본이 바뀌면, 그에 맞춰 캐시에 보관된 데이터도 함께 변경하거나 삭제해야 한다.  
캐시에 저장된 데이터의 특성에 따라 캐시를 무효화하는 시점을 달리 설정해야한다. 가격 정보, 게시글 내용처럼 민감한 데이터는 변경되는 즉시 캐시를 무효화해야한다.  
변경에 민감한 데이터는 로컬 캐시가 아닌 리모트 캐시에 보관해야 한다.  
변경에 민감하지 않고 데이터 크기가 작다면 캐시의 유효 시간을 설정하여 주기적으로 갱신하는 방식을 사용해도 된다. 최근 인기 글 목록을 캐시에 저장한 경우, 최근 인기글 목록이 바뀌고 몇 분 뒤에 캐시 데이터가 변경되더라도 서비스에 심각한 문제가 일어나지 않는다.

### 가비지 컬렉터와 메모리 사용

실제 애플리케이션이 사용하는 메모리를 고려하여 힙 메모리를 설정 해주어야한다. 만일 실제 애플리케이션이 4GB에 가까운 메모리가 있어야하는데도 2GB로 줄이면 메모리 부족으로 에러가 발생할 수 있다.  
한번에 대량으로 객체를 생성하는 것도 주의해아한다. 대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다. 최대 3개월 치만 거래 내역을 조회할 수 있게 하는 식으로 말이다.  
파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다. 파일 데이터를 한꺼번에 메모리에 로딩한 후에 응답하는 방식은 피해야한다. 파일 크기와 동시 사용자 수에 따라 메모리 사용량이 급증할 수 있기 때문이다. 아래 코드는 30MB 크기의 파일을 100명이 동시에 다운로드하면 약 3GB의 메모리가 필요하게 된다.

```java
byte[] bytes = Files.readAllBytes(Path.of("path")); //파일을 한 번에 메모리에 로딩
out.write(bytes);
```

스트림을 활용하면 파일 처리 과정에서 필요한 메모리 크기를 줄일 수 있다.

### 응답 데이터 압축

웹 브라우저나 클라이언트는 Accept-Encoding 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다.  
웹 서버는 Accept-Encoding 헤더에 명시된 알고리즘 중에서 자신이 지원하는 방식이 있을 경우, 해당 압축 알고리즘으로 응답 데이터를 압축해서 전송한다. 이때 사용된 압축 알고리즘은 Content-Encoding 응답 헤더를 통해 클라이언트에 전달된다.

응답 데이터를 압축할 때는 다음 사항을 고려하자.

- HTML, CSS, JS, JSON 과 같은 텍스트 형식의 압축률이 높아 효과적이다. 반면 jpeg 이미지나 zip 파일처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다. 모든 응답에 압축을 적용하지 말고 텍스트 형식의 데이터에 압축을 적용하자
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않았다면 방화벽 설정도 확인해야 한다.

> **트래픽과 비용**  
> 응답 데이터의 크기는 곧 비용이다. AWS와 같은 클라우드 서비스는 트래픽 양에 비례해서 과금한다.

### 정적 자원과 브라우저캐시

서버는 2가지 종류의 데이터를 응답한다.

1. 동적 자원: 브라우저가 요청할 때마다 결과가 바뀌는 데이터로 제품 목록 HTML이나 제품 상세 JSON 응답이 해당한다.
2. 정적 자원: 같은 URL에 대해 같은 데이터를 응답하는 콘텐츠로 이미지, JS, CSS가 대표적이다.

정적 자원은 전체 트래픽에서 상당한 비중을 차지한다. 이미지가 많은 쇼핑몰 사이트의 첫 페이지는 정적 자원이 전체 데이터의 80%를 차지하기도 한다.

동일한 페이지를 들어갈 때마다 같은 이미지나 JS 파일을 매번 다운로드하면 서버 입장에서 좋을 게 없다. **트래픽은 비용과 연결된다.**

클라이언트 캐시를 활용하여 트래픽을 줄이면서 브라우저가 더 빠르게 화면을 표시할 수 있는 방법이 있다.  
 HTTP 프로토콜에서는 데이터를 응답할 때 Cache-Control이나 Expires 헤더를 이용해 클라이언트가 응답 데이터를 일정 시간 동안 저장해 둘 수 있도록 설정할 수 있다.

https://도메인주소/a.png 라는 이미지의 응답 헤더에 Cache-Control 헤더 값이 다음과 같이 지정되어 있다고 하자.

```
Cache-Control: max-age=60
```

브라우저는 https://도메인주소/a.png 같은 주소로부터 a.png 파일을 다운로드하면, 해당 파일을 로컬 캐시(메모리나 디스크)에 보관한다. 이후 같은 주소를 60초 이내에 다시 요청하면 서버에 요청을 보내지 않고 로컬에 보관한 데이터를 사용해서 표시한다. 로컬에서 불러오기 때문에 처리 속도도 빨리진다.  
브리우저 캐시를 활용하면 서버 입장에서도 전송해야할 트래픽이 줄어들고, 네트워크 전송 비용을 아낄 수 있다.

### 정적 자원과 CDN

브라우저 캐시는 브라우저 단위로 캐싱하므로 네트워크 트래픽은 줄어들지만, 동시에 많은 사용자가 접속하면 순간적으로 많은 양의 이미지, js, css를 전송하게 된다. (각 사용자마다 브라우저 단위로 요청하므로)  
위 문제를 해결하는 방법인 CDN(Content Delivery Network)(콘텐츠 전송 네트워크)를 사용하는 것이다.  
콘텐츠를 제공하기 위한 별도의 네트워크를 의미한다.  
사용자는 CDN이 제공하는 URL을 통해 콘텐츠에 접근한다. CDN 서버에 요청한 콘텐츠가 없으면 오리진 서버에서 읽어와 제공한다. 즉, 동일한 콘텐츠를 여러 번 요청해도 오리진 서버는 한 번만 처리하면 되는 것이다. 나머지는 CDN이 맡는다. 이처럼 이미지, JS 같은 정적 자원을 CDN으로 제공하면 오리진 서버가 처리해야 할 트래픽을 상당히 줄일 수 있다.  
CDN은 여러 지역에 서버를 둔다. 사용자는 가까운 곳에 위치한 서버에 연결해서 콘텐츠를 다운로드한다. 이로 인해 콘텐츠를 빠르게 받을 수 있고, 이미지나 JS 파일이 빠르게 로드되는만큼 브라우저도 더 빠르게 화면을 표시할 수 있다. 또한 CDN을 활용하면 오리진 서버에서 직접 콘텐츠를 제공하는 것보다 트래픽 비용도 적게 든다.

서비스가 성장하기 시작했다면 오리진 서버의 트래픽 감소, 콘텐츠의 빠른 제공, 트래픽 비용 절감이라는 장점이 있는 CDN 사용을 고려해보자.

### 대기 처리

> 디비를 쉽게 증설할 수 없느 이유는 데이터 동기화 문제 때문?

순간적으로 폭증하는 트래픽을 감당하기 위해 서버와 DB를 증설해야한다. 클라우드를 사용한다면 서버를 쉽게 증설할 수 있다. DB는 쉽게 증설할 수 없기에 예상되는 트래핏에 맞춰 미리 증설해야한다.  
순간적으로 폭증하는 트래핏을 처리하기 위해 서버와 DB 증설이 잘못된 방법은 아니지만 비용 문제가 있다. 최대 트래픽에 맞춰 DB 성능을 높여놓으면 다시 성능을 줄이기 쉽지 않다. 전체 서비스 시간 중 1%도 안되는 시간을 위해 고정 비용(DB비용)이 커지는 격이다.  
처리할 수 있는 시스템의 처리량을 무작정 늘리기보다는 수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리하는 것이다.  
트래픽이 순간적으로 증가할 때 동시에 수용할 사용자 수를 제한하고 나머지 사용자를 대기 처리하면 다음의 이점을 얻을 수 있다.

- 서버를 증설하지 않고도 서비스를 안정적으로 제공할 수 있다.
- 사용자의 지속적인 새로고침으로 인한 트래픽 폭증도 방지할 후 있다. 사용자는 새로고침할 경우 순번이 뒤로 밀리기 때문에 불필요한 새로고침을 자제하게 된다.

```
서버 개발자라면 누구나 한 번쯤 대규모 트래픽을 처리할 수 있는 아키텍처를 경험해보고 싶겠지만 비용도 생각해야 한다. 대규모 트래픽을 처리하기 위해 지불해야할 비용은 결코 적지 않다. 이런 관점에서 대기 제어는 매우 합리적인 방식이라고 할 수 있다.
대기 제어 기능을 직접 구현할 필요도 없다. 이미 여러 솔루션이 존재하고 있어 빠르게 도입할 수 있다는 것도 큰 장점이다.
```

### 논의해 본 것

> 최대 TPS같은 경우 어떻게 측정? 책에서는 1초를 기준으로 5개의 요청을 처리할 수 있으니까 최대 TPS가 5가된다고 하였는데, 측정 기준이 애매한 것 같다? 0.5 초를 기준으로 최대 TPS 를 측정할 수 도 있는거 아닌가... TPS가 기본적으로 초당 트랜잭션 수 임

> TPS 수를 늘리기 위해 동시에 처리할 수 있는 요청 수를 늘리는 방법으로는 어떤게 있을까? 서버 확장이 있음 수평 확장, 수직 확장  
> 수평 확장은 요청을처리할 수 있는 서버가 늘어나는 것이니 자연스럽게 동시에 처리할 수 있는 요청이 늘어날 것이다.  
> 수직 확장의 경우 동시에 실행되어야하니 스레드 풀에 스레드가 많아야하고, 스레드가 많으면 서버 자원을 동시에 많이 사용하게 될 것이고, DB 부하도 신경써야함. -> 한계: 자원을 무한대로 늘릴 수는 없음.

만일 개인 프로젝트에서 일시적으로 트래픽 늘려서 부하를 시킨 후 동시에 처리할 수 있는 요청 수를 늘리기 위해서는 어떤 방식이 적당할 지 생각해봐야한다. 동시 요청 수를 늘리기보다는 sql 실행 횟수 줄이는 방법, 캐시 이용해서 서버 접근 줄이기 등 적은 비용으로 응답 시간 줄이는 것을 우선적으로 해보기, 수평, 수직 확장은 최후의 선택 방안.  
급한 불을 끄고 싶다면 수평 확장으로 해 놓고, 나중에 수정하기도 한다.

> 최대 유휴 시간, 최대 유지 시간은 RDBMS에서 일정시간동안 상작용이 없으면 자동으로 연결이 끊기는 시간을 기준으로 설정하면 될 거 같음 최대 유지 시간은 어떤 값을 기준으로 설정하는게 좋은가? 너무 짧으면 커넥션을 재시작해야해서 응답 시간이 길어짐. 너무 길면 DB와의 커넥션이 끊겼는데 풀에서는 유효한 커넥션으로 남아 있을 수 있음.

부하가 심할 때와 아닐때, 커넥션 풀, 최대 유휴 시간, 최대 유지 시간을 어떻게 설정해야하는 것일까?

> 커넥션 풀 크기는 어떻게 설정할 것인가? 크면 무조건적으로 좋은가? DB 부하를 살펴봐야한다. DB의 CPU 사용률을 확인하고 커넥션을 늘려도 DB가 감당 가능하면 커넥션 풀을 늘려도 된다. 하지만 DB 에 부하가 심하다면? 커넥션을 늘려도 응답시간이 빨리지진 않는다.  
> _커넥션 풀이 제공하는 설정을 동적으로 변경할 수 있는가? -> 알아보기_

피크 타임에 맞춰서 최대 유지시간을 늘리고, 최대 유휴시간은 대량 트래픽이 발생하는 시점을 찾아서 평균을 내어서 설정하는게 맞다고 본다.

### 적용해 볼 것들

```
상명위키의 최신 게시글 목록 -> 몇시간에 며칠동안 동일함 (트래픽 없으니까) 자주 바뀌지 않고 크기가 작은 데이터는 로컬 캐시로 활용 -> 서버 재시작하게 되면 처음에만 조금 응답 시간이 오래걸리고 그 이후로 캐시를 사용하므로 응답시간이 줄어들 것임

브라우저 캐시, 로컬 캐시, 리모트 캐시
 CDN은 너무 무거움. 최신 게시글은 원본 데이터가 변경되어서 캐시에 반영되지 않아도 큰 문제가 없음.
```

```
jwt 사용할 때 캐시로 레디스를 사용했는데, 이때 TTL은 토큰의 만료시간과 동일하게 설정하였다.
위 같은 경우가 캐시에서 오래된 데이터를 삭제하는 것과 동일한 맥락인가
```
